name: ğŸŒ©ï¸ Build, Push, Deploy SkillBridge (EKS + API Gateway)

on:
    push:
        branches: [deploy]
    workflow_dispatch:

env:
    AWS_REGION: ap-southeast-1
    STACK_A: skillbridge-infra
    STACK_B: skillbridge-apigw
    CLUSTER_NAME: skillbridge-eks
    NAMESPACE: skillbridge
    IMAGE_TAG: ${{ github.sha }}

jobs:
    deploy:
        runs-on: ubuntu-latest
        permissions:
            id-token: write
            contents: read

        steps:
            # ğŸ§¾ Checkout
            - name: ğŸ§¾ Checkout Repository
              uses: actions/checkout@v4

            # âš™ï¸ AWS Creds
            - name: âš™ï¸ Configure AWS Credentials
              uses: aws-actions/configure-aws-credentials@v4
              with:
                  aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
                  aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
                  aws-region: ${{ env.AWS_REGION }}

            - name: ğŸ” Verify AWS Identity
              run: |
                  echo "ğŸ”‘ Checking AWS credentials..."
                  aws sts get-caller-identity
                  echo "âœ… AWS credentials verified."

            # â˜ï¸ Deploy infra stack
            - name: â˜ï¸ Deploy Stack A (VPC + EKS + ECR)
              run: |
                  echo "ğŸš§ Deploying CloudFormation stack: $STACK_A ..."
                  aws cloudformation deploy \
                    --stack-name $STACK_A \
                    --template-file cloudformation/infra.yaml \
                    --capabilities CAPABILITY_NAMED_IAM \
                    --no-fail-on-empty-changeset
                  echo "âœ… Stack $STACK_A deployed."

            # ğŸ“¡ kubeconfig
            - name: ğŸ“¡ Update kubeconfig
              run: |
                  echo "ğŸ” Updating kubeconfig for cluster $CLUSTER_NAME ..."
                  aws eks update-kubeconfig --name $CLUSTER_NAME --region $AWS_REGION
                  echo "âœ… kubeconfig ready."

            # ğŸ§± Install dependencies for LoadBalancer Controller
            - name: ğŸ§° Install eksctl, kubectl, and helm
              run: |
                  echo "ğŸ“¦ Installing eksctl..."
                  curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
                  sudo mv /tmp/eksctl /usr/local/bin
                  echo "âœ… eksctl installed: $(eksctl version)"

                  echo "ğŸ“¦ Installing kubectl..."
                  # Fetch the cluster version dynamically
                  CLUSTER_VERSION=$(aws eks describe-cluster --name $CLUSTER_NAME --region $AWS_REGION --query "cluster.version" --output text)
                  echo "ğŸ” EKS cluster version: $CLUSTER_VERSION"

                  # Download kubectl using the correct stable URL format
                  curl -LO "https://dl.k8s.io/release/v${CLUSTER_VERSION}.0/bin/linux/amd64/kubectl"
                  chmod +x kubectl
                  sudo mv kubectl /usr/local/bin/
                  echo "âœ… kubectl installed: $(kubectl version --client --short)"

                  echo "ğŸ“¦ Installing helm..."
                  curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
                  echo "âœ… helm installed: $(helm version --short)"

            # ğŸ§± Install AWS LoadBalancer Controller
            - name: ğŸ§± Install AWS LoadBalancer Controller
              run: |
                  echo "ğŸš€ Installing AWS LoadBalancer Controller..."

                  # Update kubeconfig
                  aws eks update-kubeconfig --name $CLUSTER_NAME --region $AWS_REGION

                  # Associate OIDC provider
                  echo "ğŸ” Checking OIDC provider..."
                  eksctl utils associate-iam-oidc-provider --cluster $CLUSTER_NAME --region $AWS_REGION --approve

                  # Download and create IAM policy
                  curl -s -o iam-policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/main/docs/install/iam_policy.json

                  ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
                  POLICY_ARN="arn:aws:iam::${ACCOUNT_ID}:policy/AWSLoadBalancerControllerIAMPolicy"

                  # Create policy if it doesn't exist
                  aws iam create-policy \
                    --policy-name AWSLoadBalancerControllerIAMPolicy \
                    --policy-document file://iam-policy.json 2>/dev/null || echo "â„¹ï¸ Policy already exists."

                  # Delete existing service account and wait for cleanup
                  echo "ğŸ§¹ Cleaning up existing service account..."
                  eksctl delete iamserviceaccount \
                    --cluster=$CLUSTER_NAME \
                    --namespace=kube-system \
                    --name=aws-load-balancer-controller \
                    --region $AWS_REGION \
                    --wait 2>/dev/null || echo "â„¹ï¸ No existing service account"

                  # Wait a moment for cleanup
                  sleep 10

                  # Create NEW service account with IAM role
                  echo "ğŸ”§ Creating service account with IAM role..."
                  eksctl create iamserviceaccount \
                    --cluster=$CLUSTER_NAME \
                    --namespace=kube-system \
                    --name=aws-load-balancer-controller \
                    --attach-policy-arn=${POLICY_ARN} \
                    --region $AWS_REGION \
                    --approve

                  # Verify service account was created
                  echo "âœ… Verifying service account..."
                  kubectl get serviceaccount aws-load-balancer-controller -n kube-system

                  # Get VPC ID
                  VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=skillbridge-vpc" --query "Vpcs[0].VpcId" --output text)
                  echo "ğŸ§© VPC detected: $VPC_ID"

                  # Uninstall existing controller if present
                  echo "ğŸ§¹ Removing any existing controller installation..."
                  helm uninstall aws-load-balancer-controller -n kube-system 2>/dev/null || echo "â„¹ï¸ No existing installation"

                  # Wait for cleanup
                  sleep 5

                  # Apply CRDs
                  echo "ğŸ“‹ Applying CRDs..."
                  kubectl apply -k "github.com/aws/eks-charts/stable/aws-load-balancer-controller/crds?ref=master"

                  # Add helm repo
                  echo "ğŸ“¦ Setting up Helm repository..."
                  helm repo add eks https://aws.github.io/eks-charts
                  helm repo update

                  # Install controller
                  echo "ğŸš€ Installing AWS Load Balancer Controller via Helm..."
                  helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
                    -n kube-system \
                    --set clusterName=$CLUSTER_NAME \
                    --set serviceAccount.create=false \
                    --set serviceAccount.name=aws-load-balancer-controller \
                    --set region=$AWS_REGION \
                    --set vpcId=$VPC_ID

                  # Wait for deployment to be created
                  echo "â³ Waiting for deployment to be created..."
                  for i in {1..30}; do
                    if kubectl get deployment aws-load-balancer-controller -n kube-system &>/dev/null; then
                      echo "âœ… Deployment created"
                      break
                    fi
                    echo "ğŸ”„ Waiting for deployment... ($i/30)"
                    sleep 2
                  done

                  # Wait for controller pods to be ready
                  echo "â³ Waiting for controller pods to be ready..."
                  kubectl wait --for=condition=available --timeout=300s \
                    deployment/aws-load-balancer-controller -n kube-system

                  # Verify controller is running
                  echo "ğŸ” Verifying controller status..."
                  kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller

                  echo "âœ… AWS LoadBalancer Controller installed successfully."

            # ğŸ— Namespace
            - name: ğŸ—ï¸ Create Namespace
              run: |
                  kubectl get ns $NAMESPACE || kubectl create ns $NAMESPACE
                  echo "âœ… Namespace $NAMESPACE ready."

            # ğŸ” Secrets
            - name: ğŸ” Create app-secrets
              run: |
                  echo "ğŸ”‘ Creating app-secrets..."
                  kubectl -n $NAMESPACE delete secret app-secrets --ignore-not-found
                  kubectl -n $NAMESPACE create secret generic app-secrets \
                    --from-literal=ACCESS_KEY_ID="${{ secrets.AWS_S3_ACCESS_KEY_ID }}" \
                    --from-literal=SECRET_ACCESS_KEY="${{ secrets.AWS_S3_SECRET_ACCESS_KEY }}" \
                    --from-literal=STRIPE_SECRET_KEY="${{ secrets.STRIPE_SECRET_KEY }}" \
                    --from-literal=MONGODB_URI="${{ secrets.MONGODB_URI }}"
                  echo "âœ… app-secrets created."

            # ğŸ§© ConfigMaps
            - name: ğŸ§© Apply ConfigMaps
              run: |
                  echo "ğŸ“¦ Applying ConfigMaps..."
                  if [ -d k8s/configmaps ]; then
                    kubectl apply -f k8s/configmaps/ -n $NAMESPACE
                  else
                    echo "â„¹ï¸ No configmaps folder found, skipping."
                  fi

            # ğŸ³ Build + Push
            - name: ğŸ³ Build & Push Service Images
              run: |
                  ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
                  REGISTRY="${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"
                  aws ecr get-login-password --region ${AWS_REGION} | docker login --username AWS --password-stdin ${REGISTRY}

                  services=( user-service availability-service search-service booking-service payment-service file-service pair-programming-service messaging-service )

                  for SERVICE in "${services[@]}"; do
                    echo "ğŸ” Checking $SERVICE..."
                    
                    # Check if image exists in ECR
                    if aws ecr describe-images --repository-name ${SERVICE} --image-ids imageTag=${IMAGE_TAG} --region ${AWS_REGION} >/dev/null 2>&1; then
                      echo "ğŸ“¦ Image ${SERVICE}:${IMAGE_TAG} exists in ECR"
                      
                      # Image exists, check for code changes
                      if git rev-parse HEAD~1 >/dev/null 2>&1; then
                        PREV_COMMIT="HEAD~1"
                      else
                        PREV_COMMIT=$(git rev-list --max-parents=0 HEAD)
                      fi
                      
                      if git diff --quiet $PREV_COMMIT HEAD -- services/$SERVICE/; then
                        echo "âšª No changes detected in $SERVICE â€” skipping build."
                        continue
                      else
                        echo "ğŸ”„ Code changes detected in $SERVICE â€” rebuilding..."
                      fi
                    else
                      echo "ğŸ†• Image ${SERVICE}:${IMAGE_TAG} not found in ECR â€” building..."
                    fi
                    
                    # Build and push
                    echo "âš™ï¸ Building image for $SERVICE..."
                    docker build -t ${SERVICE}:latest ./services/${SERVICE}
                    docker tag ${SERVICE}:latest ${REGISTRY}/${SERVICE}:${IMAGE_TAG}
                    docker tag ${SERVICE}:latest ${REGISTRY}/${SERVICE}:latest
                    docker push ${REGISTRY}/${SERVICE}:${IMAGE_TAG}
                    docker push ${REGISTRY}/${SERVICE}:latest
                    echo "âœ… $SERVICE pushed successfully."
                  done

            # ğŸš€ Deployments
            - name: ğŸš€ Apply Services & Deployments
              run: |
                  echo "ğŸ“¦ Preparing deployments with environment variable substitution..."

                  # Get AWS account ID and region
                  export AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
                  export AWS_REGION="${AWS_REGION}"
                  export IMAGE_TAG="${IMAGE_TAG}"

                  echo "ğŸ”§ AWS_ACCOUNT_ID: $AWS_ACCOUNT_ID"
                  echo "ğŸ”§ AWS_REGION: $AWS_REGION"
                  echo "ğŸ”§ IMAGE_TAG: $IMAGE_TAG"

                  # Check if envsubst is available, install if not
                  if ! command -v envsubst &> /dev/null; then
                    echo "ğŸ“¦ Installing gettext-base for envsubst..."
                    sudo apt-get update && sudo apt-get install -y gettext-base
                  fi

                  # Substitute environment variables and apply
                  echo "ğŸ”„ Substituting environment variables in deployments..."
                  envsubst < k8s/services-deployments.yaml | kubectl apply -f - -n $NAMESPACE

                  echo "âœ… All deployments applied with correct image references."

                  # Wait a moment for deployments to be created
                  sleep 5

                  # Show deployment status
                  echo "ğŸ“Š Deployment status:"
                  kubectl get deployments -n $NAMESPACE

            # ğŸŒ Edge Nginx
            - name: ğŸŒ Apply Edge NGINX (ConfigMap + Deployment + Service)
              run: |
                  echo "ğŸ§­ Applying edge NGINX gateway..."
                  kubectl apply -f k8s/edge-nginx-configmap.yaml -n $NAMESPACE
                  kubectl apply -f k8s/edge-nginx-deployment.yaml -n $NAMESPACE
                  echo "âœ… Edge NGINX applied."

            - name: ğŸ” Debug Load Balancer Controller
              run: |
                  echo "ğŸ“‹ Checking AWS Load Balancer Controller status..."
                  kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller

                  echo "ğŸ“œ Controller logs (last 50 lines):"
                  kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller --tail=50 || echo "âš ï¸ Could not fetch logs"

                  echo "ğŸ” Checking service status:"
                  kubectl describe svc edge-nginx -n $NAMESPACE

                  echo "ğŸ“‹ Recent events:"
                  kubectl get events -n $NAMESPACE --sort-by=.metadata.creationTimestamp | tail -n 30

            # â³ Wait for NLB
            - name: â³ Wait for Edge NLB & Capture DNS
              id: nlb
              run: |
                  echo "ğŸ•’ Waiting for NLB hostname..."
                  for i in {1..60}; do
                    DNS=$(kubectl -n $NAMESPACE get svc edge-nginx -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || true)
                    TYPE=$(kubectl -n $NAMESPACE get svc edge-nginx -o jsonpath='{.spec.type}' 2>/dev/null || true)
                    echo "ğŸ” Attempt $i/60 | Type=$TYPE | DNS=${DNS:-N/A}"
                    if [ -n "$DNS" ]; then
                      echo "âœ… NLB ready! Hostname: $DNS"
                      echo "dns=$DNS" >> $GITHUB_OUTPUT
                      break
                    fi
                    sleep 10
                  done

                  if [ -z "$(kubectl -n $NAMESPACE get svc edge-nginx -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null)" ]; then
                    echo "âŒ Edge NLB not ready after 10 minutes."
                    echo "ğŸ” Describing service..."
                    kubectl describe svc edge-nginx -n $NAMESPACE || true
                    echo "ğŸ“‹ Recent events:"
                    kubectl get events -n $NAMESPACE --sort-by=.metadata.creationTimestamp | tail -n 20
                    echo "ğŸ’¡ Tips:"
                    echo "   - Ensure AWS LoadBalancer Controller is running (kubectl get pods -n kube-system)."
                    echo "   - Verify IAM permissions for NLB creation."
                    exit 1
                  fi

            # ğŸ”— Resolve Listener ARN
            - name: ğŸ”— Resolve NLB Listener ARN from DNS
              id: nlblistener
              run: |
                  echo "ğŸ” Resolving NLB ARN for DNS: ${{ steps.nlb.outputs.dns }}"

                  # Get NLB ARN from DNS name
                  NLB_ARN=$(aws elbv2 describe-load-balancers \
                    --query "LoadBalancers[?DNSName=='${{ steps.nlb.outputs.dns }}'].LoadBalancerArn" \
                    --output text)

                  if [ -z "$NLB_ARN" ]; then
                    echo "âŒ Could not resolve NLB ARN from DNS."
                    exit 1
                  fi

                  echo "âœ… Found NLB ARN: $NLB_ARN"

                  # Get Listener ARN from NLB ARN
                  echo "ğŸ” Getting Listener ARN for NLB..."
                  LISTENER_ARN=$(aws elbv2 describe-listeners \
                    --load-balancer-arn "$NLB_ARN" \
                    --query "Listeners[0].ListenerArn" \
                    --output text)

                  if [ -z "$LISTENER_ARN" ] || [ "$LISTENER_ARN" == "None" ]; then
                    echo "âŒ Could not find Listener ARN for NLB."
                    echo "ğŸ“‹ Available listeners:"
                    aws elbv2 describe-listeners --load-balancer-arn "$NLB_ARN" || true
                    exit 1
                  fi

                  echo "âœ… Found Listener ARN: $LISTENER_ARN"
                  echo "listener_arn=$LISTENER_ARN" >> $GITHUB_OUTPUT

            # â˜ï¸ Deploy API Gateway
            - name: â˜ï¸ Deploy Stack B (API Gateway)
              env:
                  DOMAIN_NAME: ${{ secrets.API_DOMAIN_NAME }}
                  CERT_ARN: ${{ secrets.API_DOMAIN_CERT_ARN }}
                  HOSTED_ZONE_ID: ${{ secrets.ROUTE53_HOSTED_ZONE_ID }}
              run: |
                  echo "ğŸš€ Deploying API Gateway Stack..."
                  echo "ğŸ”§ Using Listener ARN: ${{ steps.nlblistener.outputs.listener_arn }}"

                  aws cloudformation deploy \
                    --stack-name $STACK_B \
                    --template-file cloudformation/apigw.yaml \
                    --parameter-overrides \
                      ProjectName=skillbridge \
                      CustomDomainName=${DOMAIN_NAME} \
                      CertificateArn=${CERT_ARN} \
                      EdgeNlbListenerArn=${{ steps.nlblistener.outputs.listener_arn }} \
                      StageName=prod \
                      HostedZoneId=${HOSTED_ZONE_ID} \
                    --no-fail-on-empty-changeset

                  echo "âœ… API Gateway deployed successfully."

            # ğŸ“¡ Show Endpoint
            - name: ğŸ“¡ Show API Gateway Endpoint
              run: |
                  echo "ğŸ” Fetching API Gateway endpoint..."
                  API=$(aws cloudformation describe-stacks \
                    --stack-name $STACK_B \
                    --query "Stacks[0].Outputs[?OutputKey=='ApiInvokeUrl'].OutputValue" \
                    --output text)

                  DEFAULT_API=$(aws cloudformation describe-stacks \
                    --stack-name $STACK_B \
                    --query "Stacks[0].Outputs[?OutputKey=='ApiDefaultUrl'].OutputValue" \
                    --output text)

                  echo "âœ… Deployment Complete!"
                  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
                  echo "ğŸŒ Custom Domain API Endpoint: $API"
                  echo "ğŸ”— Default API Gateway URL: $DEFAULT_API"
                  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
